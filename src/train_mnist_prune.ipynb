{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Large-Scale Dataset Pruning with Dynamic Uncertainty for MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementation according to \"Large-scale Dataset Pruning with Dynamic Uncertainty\" (https://arxiv.org/abs/2306.05175)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Objective:**\n",
    "\n",
    "    \"Implement data pruning using the dynamic uncertainty score on the MNIST dataset and train a model with 25% and 50% pruning (i.e., 25% or 50% of the data is removed for the final training using the calculated pruning scores). Compare your implementation with random subsampling of the data. Additionally, implement the following custom dynamic uncertainty score U(x) = abs(DFT(x)), where DFT is the Discrete Fourier Transform and abs takes the magnitude of the frequency spectrum. Consider the following: Do we need every value of the DFT, or can we remove some and get the same result? If we only want to consider the dynamics, which values do we need to remove? \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "\n",
    "from torchvision.datasets import MNIST\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "pruning_ratio = 0.25\n",
    "epochs = 10\n",
    "crit = nn.CrossEntropyLoss()\n",
    "J = 5 # J < epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eval accuracy of a given net on a given loader\n",
    "def eval_acc(net, loader : DataLoader):\n",
    "    net.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(loader, desc=f'Test acc'):\n",
    "            outputs = net(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = correct / total\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0244,  0.0529,  0.2159, -0.0866, -0.0318,  0.2499, -0.1300,  0.0026,\n",
      "         -0.2277, -0.2908],\n",
      "        [ 0.1704,  0.1435,  0.1600, -0.0016, -0.0947,  0.3685, -0.1382, -0.0325,\n",
      "         -0.2190, -0.3119]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=8, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=8, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc = nn.Linear(in_features=14*14*16, out_features=10)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "        # x = self.softmax(x)\n",
    "        return x\n",
    "    \n",
    "# Test model \n",
    "x_random = torch.randn((2,1,28,28))\n",
    "net = CNN()\n",
    "print(net(x_random))\n",
    "del net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize((0.1307,), (0.3081,)) # Mean and std of MNIST dataset\n",
    "        ])\n",
    "\n",
    "trainset = MNIST(root='../data', train=True, download=True, transform=transform)\n",
    "testset = MNIST(root='../data', train=False, download=True, transform=transform)\n",
    "\n",
    "# Just shuffle once initially!\n",
    "indices = torch.randperm(len(trainset))\n",
    "train_size = int(0.8 * len(indices))\n",
    "val_size = len(indices) - train_size\n",
    "subset_size = int((1 - pruning_ratio) * train_size)\n",
    "train_indices, val_indices = indices[:train_size], indices[train_size:]\n",
    "\n",
    "train_subset = Subset(trainset, train_indices)\n",
    "val_subset = Subset(trainset, val_indices)\n",
    "\n",
    "trainloader = DataLoader(train_subset, batch_size=batch_size, shuffle=False)\n",
    "valloader =  DataLoader(val_subset, batch_size=batch_size, shuffle=False)\n",
    "testloader = DataLoader(testset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainset size: 48000\n",
      "Validation size: 12000\n",
      "Subset size: 36000\n",
      "Teset size: 10000\n"
     ]
    }
   ],
   "source": [
    "print(f\"Trainset size: {train_size}\")\n",
    "print(f\"Validation size: {val_size}\")\n",
    "print(f\"Subset size: {subset_size}\")\n",
    "print(f\"Teset size: {len(testset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Baseline** (full dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_baseline = CNN()\n",
    "optimizer_baseline = AdamW(net_baseline.parameters())\n",
    "name_baseline = f\"baseline_{epochs}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:   1%|          | 11/1500 [00:00<00:48, 30.68it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|██████████| 1500/1500 [00:35<00:00, 42.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Average Loss: 0.0059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: 100%|██████████| 1500/1500 [00:27<00:00, 53.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10, Average Loss: 0.0020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: 100%|██████████| 1500/1500 [00:27<00:00, 53.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10, Average Loss: 0.0014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: 100%|██████████| 1500/1500 [00:27<00:00, 53.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10, Average Loss: 0.0011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: 100%|██████████| 1500/1500 [00:28<00:00, 51.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10, Average Loss: 0.0009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10: 100%|██████████| 1500/1500 [00:28<00:00, 52.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10, Average Loss: 0.0007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10: 100%|██████████| 1500/1500 [00:27<00:00, 54.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10, Average Loss: 0.0006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10: 100%|██████████| 1500/1500 [00:27<00:00, 53.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10, Average Loss: 0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10: 100%|██████████| 1500/1500 [00:27<00:00, 53.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10, Average Loss: 0.0004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|██████████| 1500/1500 [00:28<00:00, 52.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10, Average Loss: 0.0004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    total_loss = 0.0\n",
    "    for inputs, labels in tqdm(trainloader, desc=f'Epoch {epoch + 1}/{epochs}'):\n",
    "        optimizer_baseline.zero_grad()\n",
    "        outputs = net_baseline(inputs)\n",
    "        loss = crit(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer_baseline.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    average_loss = total_loss / train_size\n",
    "    print(f'Epoch {epoch + 1}/{epochs}, Average Loss: {average_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test acc: 100%|██████████| 313/313 [00:04<00:00, 74.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 98.41%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'Test Accuracy: {eval_acc(net=net_baseline, loader=testloader) * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net_baseline.state_dict(), f\"../models/{name_baseline}.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Random Subsampling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_subsampling = CNN()\n",
    "optimizer_subsampling = AdamW(net_subsampling.parameters())\n",
    "name_subsampling = f\"subsampling_{pruning_ratio}_{epochs}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import SubsetRandomSampler\n",
    "idxs = torch.randperm(train_size)[:subset_size]\n",
    "sampler = SubsetRandomSampler(idxs)\n",
    "randomsubsampledloader = DataLoader(trainloader.dataset, batch_size=batch_size, sampler=sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|██████████| 1125/1125 [00:23<00:00, 48.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Average Loss: 0.0065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: 100%|██████████| 1125/1125 [00:20<00:00, 54.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10, Average Loss: 0.0021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: 100%|██████████| 1125/1125 [00:20<00:00, 53.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10, Average Loss: 0.0015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: 100%|██████████| 1125/1125 [00:21<00:00, 53.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10, Average Loss: 0.0012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: 100%|██████████| 1125/1125 [00:21<00:00, 52.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10, Average Loss: 0.0009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10: 100%|██████████| 1125/1125 [00:20<00:00, 54.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10, Average Loss: 0.0007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10: 100%|██████████| 1125/1125 [00:21<00:00, 52.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10, Average Loss: 0.0006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10: 100%|██████████| 1125/1125 [00:20<00:00, 54.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10, Average Loss: 0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10: 100%|██████████| 1125/1125 [00:20<00:00, 54.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10, Average Loss: 0.0004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|██████████| 1125/1125 [00:20<00:00, 53.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10, Average Loss: 0.0003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    total_loss = 0.0\n",
    "    for inputs, labels in tqdm(randomsubsampledloader, desc=f'Epoch {epoch + 1}/{epochs}'):\n",
    "        optimizer_subsampling.zero_grad()\n",
    "        outputs = net_subsampling(inputs)\n",
    "        loss = crit(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer_subsampling.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    average_loss = total_loss / subset_size\n",
    "    print(f'Epoch {epoch + 1}/{epochs}, Average Loss: {average_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test acc: 100%|██████████| 313/313 [00:03<00:00, 83.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 98.43%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'Test Accuracy: {eval_acc(net=net_subsampling, loader=testloader) * 100:.2f}%')\n",
    "torch.save(net_subsampling.state_dict(), f\"../models/{name_subsampling}.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**With Pruning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_pruning = CNN()\n",
    "optimizer_pruning = AdamW(net_pruning.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:  43%|████▎     | 652/1500 [00:13<00:25, 33.90it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|██████████| 1500/1500 [00:43<00:00, 34.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Average Loss: 0.0067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: 100%|██████████| 1500/1500 [00:37<00:00, 40.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10, Average Loss: 0.0027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: 100%|██████████| 1500/1500 [00:33<00:00, 44.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10, Average Loss: 0.0019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: 100%|██████████| 1500/1500 [00:33<00:00, 44.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10, Average Loss: 0.0014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: 100%|██████████| 1500/1500 [00:33<00:00, 44.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10, Average Loss: 0.0011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10: 100%|██████████| 1500/1500 [00:33<00:00, 44.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10, Average Loss: 0.0008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10: 100%|██████████| 1500/1500 [00:34<00:00, 43.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10, Average Loss: 0.0007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10: 100%|██████████| 1500/1500 [00:34<00:00, 43.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10, Average Loss: 0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10: 100%|██████████| 1500/1500 [00:34<00:00, 43.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10, Average Loss: 0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|██████████| 1500/1500 [00:34<00:00, 43.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10, Average Loss: 0.0004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Algorithm 1: Dataset pruning with dynamic uncertainty.\n",
    "# Input: Trainingset - trainloader, pruning ratio: pruning_ratio\n",
    "# Required Model: net_pruning, traing epochs: epochs, uncertainty window: J\n",
    "\n",
    "# To track uncertainty\n",
    "uncertainty_window = np.zeros((train_size, J)) # Uncertainty window\n",
    "uncertainty_EQ2 = np.zeros((train_size, epochs-J+1)) # Uncertainty according to Eq.2\n",
    "uncertainty = np.zeros(train_size) # Overall uncertainty according to Eq.3\n",
    "\n",
    "# for k = 0, · · · , K − 1 do\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0.0\n",
    "    idx = 0\n",
    "    \n",
    "    # Sample a batch B ∼ T.\n",
    "    # for (xi, yi) ∈ B do:\n",
    "    for inputs, labels in tqdm(trainloader, desc=f'Epoch {epoch + 1}/{epochs}'):\n",
    "        optimizer_pruning.zero_grad()\n",
    "\n",
    "        # Compute prediction P(yi, xi, θ) and loss ℓ(ϕθ(A(xi)), yi)\n",
    "        outputs = net_pruning(inputs)\n",
    "        loss = crit(outputs, labels)\n",
    "\n",
    "        # Store window\n",
    "        predicted_values = outputs[range(outputs.size(0)), labels]\n",
    "        uncertainty_window[idx:idx+len(labels), epoch%J] = predicted_values.detach().numpy()\n",
    "        idx += len(labels)\n",
    "\n",
    "        # Update θ ← θ − η∇θL, where L =Σℓ(ϕθ(A(xi)),yi) / |B|\n",
    "        loss.backward()\n",
    "        optimizer_pruning.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    # if k ≥ J then\n",
    "        # Compute uncertainty Uk−J (xi) using Eq. 2\n",
    "    if epoch >= J-1:\n",
    "            U_epoch = np.std(uncertainty_window, ddof=1, axis=1)\n",
    "            uncertainty_EQ2[:, epoch-J+1] = U_epoch\n",
    "\n",
    "    average_loss = total_loss / subset_size\n",
    "    print(f'Epoch {epoch + 1}/{epochs}, Average Loss: {average_loss:.4f}')\n",
    "\n",
    "# for (xi, yi) ∈ T do\n",
    "    # Compute dynamic uncertainty U(xi) using Eq. 3\n",
    "uncertainty = np.mean(uncertainty_EQ2, axis=1)\n",
    "\n",
    "# Sort T in the descending order of U(·)\n",
    "sorted_indices = np.argsort(uncertainty)[::-1]\n",
    "\n",
    "# S ← front (1 − r) × |T | samples in the sorted T\n",
    "subset_indices = sorted_indices[:int(len(sorted_indices)*(1-pruning_ratio))]\n",
    "\n",
    "# Output: Pruned dataset S\n",
    "train_dynamic_uncertainty_subset = Subset(dataset=trainloader.dataset, indices=subset_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_pruning = CNN()\n",
    "optimizer_pruning = AdamW(net_pruning.parameters())\n",
    "name_pruning = f\"pruning_{pruning_ratio}_{epochs}\"\n",
    "dynamic_uncertainty = DataLoader(train_dynamic_uncertainty_subset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|██████████| 1125/1125 [00:23<00:00, 48.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Average Loss: 0.0033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: 100%|██████████| 1125/1125 [00:22<00:00, 49.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10, Average Loss: 0.0011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: 100%|██████████| 1125/1125 [00:22<00:00, 50.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10, Average Loss: 0.0007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: 100%|██████████| 1125/1125 [00:23<00:00, 48.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10, Average Loss: 0.0004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: 100%|██████████| 1125/1125 [00:22<00:00, 49.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10, Average Loss: 0.0003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10: 100%|██████████| 1125/1125 [00:22<00:00, 49.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10, Average Loss: 0.0003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10: 100%|██████████| 1125/1125 [00:22<00:00, 50.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10, Average Loss: 0.0003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10: 100%|██████████| 1125/1125 [00:22<00:00, 49.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10, Average Loss: 0.0002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10: 100%|██████████| 1125/1125 [00:22<00:00, 49.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10, Average Loss: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|██████████| 1125/1125 [00:22<00:00, 49.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10, Average Loss: 0.0002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    total_loss = 0.0\n",
    "    for inputs, labels in tqdm(dynamic_uncertainty, desc=f'Epoch {epoch + 1}/{epochs}'):\n",
    "        optimizer_pruning.zero_grad()\n",
    "        outputs = net_pruning(inputs)\n",
    "        loss = crit(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer_pruning.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    average_loss = total_loss / train_size\n",
    "    print(f'Epoch {epoch + 1}/{epochs}, Average Loss: {average_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test acc: 100%|██████████| 313/313 [00:05<00:00, 61.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 97.93%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'Test Accuracy: {eval_acc(net=net_pruning, loader=testloader) * 100:.2f}%')\n",
    "torch.save(net_pruning.state_dict(), f\"../models/{name_pruning}.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Discrete Fourier Transform**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.fft import fft, fftn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = torch.randn((5,1,28,28))\n",
    "x_fft = fft(x_test).abs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 7.0016,  2.3408,  9.4974,  ...,  5.6659,  9.4974,  2.3408],\n",
       "          [ 3.6225,  4.8430,  3.0725,  ...,  3.4119,  3.0725,  4.8430],\n",
       "          [ 0.2753,  5.6806,  4.8276,  ...,  2.6253,  4.8276,  5.6806],\n",
       "          ...,\n",
       "          [ 0.3260,  8.0120, 11.6901,  ...,  2.6139, 11.6901,  8.0120],\n",
       "          [ 5.0772,  5.0792,  8.8253,  ...,  2.1639,  8.8253,  5.0792],\n",
       "          [ 5.1682,  3.1012,  6.1085,  ...,  4.5523,  6.1085,  3.1012]]],\n",
       "\n",
       "\n",
       "        [[[ 1.9000, 11.5732,  0.8645,  ...,  6.9359,  0.8645, 11.5732],\n",
       "          [ 0.8429,  7.1713,  1.7348,  ...,  3.8792,  1.7348,  7.1713],\n",
       "          [ 4.5909,  2.1676,  3.8562,  ...,  5.0738,  3.8562,  2.1676],\n",
       "          ...,\n",
       "          [10.2103,  6.2847,  7.5095,  ...,  4.6634,  7.5095,  6.2847],\n",
       "          [ 1.8560,  1.9186,  2.7215,  ...,  0.9371,  2.7215,  1.9186],\n",
       "          [ 2.8874,  2.0643,  1.8409,  ...,  2.2602,  1.8409,  2.0643]]],\n",
       "\n",
       "\n",
       "        [[[ 4.5337,  7.6894,  5.4230,  ...,  1.7024,  5.4230,  7.6894],\n",
       "          [ 8.3174,  1.6943,  0.8820,  ...,  4.1242,  0.8820,  1.6943],\n",
       "          [ 4.3341,  1.4760,  1.4958,  ...,  3.4460,  1.4958,  1.4760],\n",
       "          ...,\n",
       "          [ 4.3704,  7.2973,  2.8441,  ...,  6.0145,  2.8441,  7.2973],\n",
       "          [ 1.4834,  6.6168,  1.0902,  ...,  0.5611,  1.0902,  6.6168],\n",
       "          [ 9.4488,  0.2341,  1.9760,  ...,  3.0725,  1.9760,  0.2341]]],\n",
       "\n",
       "\n",
       "        [[[ 2.5137,  4.4201,  7.8734,  ...,  2.5040,  7.8734,  4.4201],\n",
       "          [ 4.6248,  7.4888,  2.1403,  ...,  5.1720,  2.1403,  7.4888],\n",
       "          [ 3.4050,  3.9870,  4.4795,  ...,  6.2752,  4.4795,  3.9870],\n",
       "          ...,\n",
       "          [ 5.3763,  4.4398,  5.4047,  ...,  5.0443,  5.4047,  4.4398],\n",
       "          [ 0.4126,  3.4277, 10.6092,  ...,  7.8179, 10.6092,  3.4277],\n",
       "          [ 6.7769, 12.3004,  7.6413,  ...,  3.4792,  7.6413, 12.3004]]],\n",
       "\n",
       "\n",
       "        [[[ 0.0889,  4.9162,  9.6148,  ...,  5.1208,  9.6148,  4.9162],\n",
       "          [ 3.6850,  7.8202,  3.9106,  ...,  6.8336,  3.9106,  7.8202],\n",
       "          [ 3.1387,  3.2669,  6.0658,  ...,  4.7676,  6.0658,  3.2669],\n",
       "          ...,\n",
       "          [ 8.0487,  3.4168,  1.0241,  ...,  3.8972,  1.0241,  3.4168],\n",
       "          [ 2.4128,  6.9789,  5.1781,  ...,  4.7750,  5.1781,  6.9789],\n",
       "          [ 1.9960,  4.6849,  5.8434,  ..., 10.4655,  5.8434,  4.6849]]]])"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_fft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_pruning = CNN()\n",
    "optimizer_pruning = AdamW(net_pruning.parameters())\n",
    "name_pruning = f\"pruning_{pruning_ratio}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 95.6847,  33.9431,  47.4507,  ...,  85.2217,  47.4507,  33.9431],\n",
       "          [ 24.1194,  97.7538,  47.1660,  ...,   3.2349,   7.6042,  64.5337],\n",
       "          [ 35.5327,  57.3047,  64.6004,  ...,  73.6595,  87.1928,  41.8536],\n",
       "          ...,\n",
       "          [ 72.6193,  52.8112,  28.6272,  ..., 103.2676,  39.9172,  57.4693],\n",
       "          [ 35.5327,  41.8536,  87.1928,  ...,  21.3594,  64.6004,  57.3047],\n",
       "          [ 24.1193,  64.5337,   7.6042,  ...,  38.8029,  47.1660,  97.7538]]],\n",
       "\n",
       "\n",
       "        [[[ 59.5293,  70.1278, 100.1183,  ...,  18.5314,  21.3645,  74.7055],\n",
       "          [ 34.4041,  77.9607,  99.2598,  ...,  67.2690,  72.3460,  20.9297],\n",
       "          [ 37.0432,  38.8848,  63.0727,  ..., 154.7969, 163.1138,  53.1937],\n",
       "          ...,\n",
       "          [ 76.3877,  38.3539,  29.4337,  ...,  29.7651,  74.1724,  58.2424],\n",
       "          [ 91.4610,  43.8345,  51.3067,  ...,  46.2332,  77.5871,  57.5014],\n",
       "          [ 39.6031,  65.3447,  64.8417,  ...,  64.9992,  52.2133,  72.0684]]],\n",
       "\n",
       "\n",
       "        [[[ 78.7171,  52.8756,  36.3424,  ...,  47.0009,  49.2732,  61.5352],\n",
       "          [ 12.5363,  63.1765,  45.8012,  ...,  62.7238,  51.8779,  66.3421],\n",
       "          [ 78.0130,   4.2265,  89.3102,  ...,  60.3754,  26.1795,  87.1584],\n",
       "          ...,\n",
       "          [131.4648,  63.9948,  76.2963,  ...,  87.8277,  53.5909,  84.4874],\n",
       "          [ 59.1289,   6.2533,  35.3402,  ...,  58.0996, 106.3888,  50.7838],\n",
       "          [ 64.1596,  22.9010,  58.1281,  ..., 120.8791,  52.7821,  36.2712]]],\n",
       "\n",
       "\n",
       "        [[[ 78.7171,  61.5352,  49.2732,  ...,  78.0355,  36.3424,  52.8756],\n",
       "          [ 64.1596,  36.2712,  52.7821,  ...,   8.6746,  58.1281,  22.9010],\n",
       "          [ 59.1289,  50.7838, 106.3888,  ...,   9.5665,  35.3402,   6.2533],\n",
       "          ...,\n",
       "          [ 32.0945,  46.6817,   9.2457,  ...,  36.8991,  49.9717,  48.3744],\n",
       "          [ 78.0130,  87.1584,  26.1795,  ...,  24.9091,  89.3102,   4.2265],\n",
       "          [ 12.5363,  66.3421,  51.8779,  ...,  57.5591,  45.8012,  63.1765]]],\n",
       "\n",
       "\n",
       "        [[[ 59.5293,  74.7055,  21.3645,  ...,  29.4535, 100.1183,  70.1278],\n",
       "          [ 39.6031,  72.0684,  52.2133,  ...,  34.7207,  64.8417,  65.3447],\n",
       "          [ 91.4610,  57.5014,  77.5871,  ..., 133.8092,  51.3067,  43.8345],\n",
       "          ...,\n",
       "          [ 41.7952,  77.1733,  86.3176,  ..., 103.2394,  29.2092, 131.3400],\n",
       "          [ 37.0432,  53.1937, 163.1138,  ...,  24.0207,  63.0727,  38.8848],\n",
       "          [ 34.4041,  20.9297,  72.3460,  ...,  33.6938,  99.2598,  77.9607]]]])"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test = torch.randn((5,1,28,28))\n",
    "fftn(x_test).abs()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
